merge (: framework {name: "pytorch", version: "1.8.1"});
merge (: module {framework: "pytorch", name: "torch", version: "1.8.1"});
match
 (m1: framework {name: "pytorch", version: "1.8.1"}),
 (m2: module {framework: "pytorch", name: "torch", version: "1.8.1"})
merge (m1) -[: classOfFramework {name: "torch"}]-> (m2);
merge (: module {framework: "pytorch", name: "optim", version: "1.8.1"});
match
 (m1: module {framework: "pytorch", name: "torch", version: "1.8.1"}),
 (m2: module {framework: "pytorch", name: "optim", version: "1.8.1"})
merge (m1) -[: subClassOfClass {name: "optim"}]-> (m2);
merge (: module {framework: "pytorch", name: "lr_scheduler", version: "1.8.1"});
match
 (m1: module {framework: "pytorch", name: "optim", version: "1.8.1"}),
 (m2: module {framework: "pytorch", name: "lr_scheduler", version: "1.8.1"})
merge (m1) -[: subClassOfClass {name: "lr_scheduler"}]-> (m2);
merge (: operator {framework: "pytorch", name: "CyclicLR", full_name: "torch.optim.lr_scheduler.CyclicLR", version: "1.8.1"});
match
 (m3: module {framework: "pytorch", name: "lr_scheduler", version: "1.8.1"}),
 (m4: operator {framework: "pytorch", name: "CyclicLR", full_name: "torch.optim.lr_scheduler.CyclicLR", version: "1.8.1"})
merge (m3) -[: operatorOfClass {name: "CyclicLR"}]-> (m4);
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 1, name: "optimizer", dtype_num: 1, dtype: " Optimizer ", optional: "False", default: ""});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 1, name: "optimizer_1", dtype : " Optimizer ", default : ""});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 2, name: "base_lr", dtype_num: 1, dtype: " float or list ", optional: "False", default: ""});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 2, name: "base_lr_1", dtype : " float or list ", default : ""});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 3, name: "max_lr", dtype_num: 1, dtype: " float or list ", optional: "False", default: ""});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 3, name: "max_lr_1", dtype : " float or list ", default : ""});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 4, name: "step_size_up", dtype_num: 1, dtype: " int ", optional: "False", default: "2000"});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 4, name: "step_size_up_1", dtype : " int ", default : "2000"});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 5, name: "step_size_down", dtype_num: 1, dtype: " int ", optional: "False", default: "None"});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 5, name: "step_size_down_1", dtype : " int ", default : "None"});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 6, name: "mode", dtype_num: 1, dtype: " str ", optional: "False", default: "‘triangular"});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 6, name: "mode_1", dtype : " str ", default : "‘triangular"});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 7, name: "gamma", dtype_num: 1, dtype: " float ", optional: "False", default: "1.0"});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 7, name: "gamma_1", dtype : " float ", default : "1.0"});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 8, name: "scale_fn", dtype_num: 1, dtype: " function ", optional: "False", default: "None"});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 8, name: "scale_fn_1", dtype : " function ", default : "None"});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 9, name: "scale_mode", dtype_num: 1, dtype: " str ", optional: "False", default: "‘cycle"});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 9, name: "scale_mode_1", dtype : " str ", default : "‘cycle"});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 10, name: "cycle_momentum", dtype_num: 1, dtype: " bool ", optional: "False", default: "True"});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 10, name: "cycle_momentum_1", dtype : " bool ", default : "True"});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 11, name: "base_momentum", dtype_num: 1, dtype: " float or list ", optional: "False", default: "0.8"});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 11, name: "base_momentum_1", dtype : " float or list ", default : "0.8"});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 12, name: "max_momentum", dtype_num: 1, dtype: " float or list ", optional: "False", default: "0.9"});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 12, name: "max_momentum_1", dtype : " float or list ", default : "0.9"});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 13, name: "last_epoch", dtype_num: 1, dtype: " int ", optional: "False", default: "-1"});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 13, name: "last_epoch_1", dtype : " int ", default : "-1"});
merge (: parameter {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", parameter_order: 14, name: "verbose", dtype_num: 1, dtype: " bool ", optional: "False", default: "False."});
merge (: childParameter  { framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", dtype_order: 1, parameter_order: 14, name: "verbose_1", dtype : " bool ", default : "False."});
merge (: return {framework: "pytorch", version: "1.8.1", operator: "torch.optim.lr_scheduler.CyclicLR", return_order: 1, name: "return", dtype: 0});
match
 (m11: operator {framework: "pytorch", full_name: "torch.optim.lr_scheduler.CyclicLR", version: "1.8.1"}),
 (n11: parameter)
where n11.operator = 'torch.optim.lr_scheduler.CyclicLR' and n11.framework = 'pytorch' and n11.version = '1.8.1'
merge (m11) -[: parameterOfOperator {parameter_order: n11.parameter_order, name: n11.name}] -> (n11);
match
 (m11: operator {framework: "pytorch", full_name: "torch.optim.lr_scheduler.CyclicLR", version: "1.8.1"}),
 (n11: input)
where n11.operator = 'torch.optim.lr_scheduler.CyclicLR' and n11.framework = 'pytorch' and n11.version = '1.8.1'
merge (m11) -[: inputOfOperator {input_order: n11.input_order, name: n11.name}] -> (n11);
match
 (m11: operator {framework: "pytorch", full_name: "torch.optim.lr_scheduler.CyclicLR", version: "1.8.1"}),
 (n11: return)
where n11.operator = 'torch.optim.lr_scheduler.CyclicLR' and n11.framework = 'pytorch' and n11.version = '1.8.1'
merge (m11) -[: returnOfOperator {return_order: n11.return_order, name: n11.name}] -> (n11);
match
 (m11: parameter {framework: "pytorch", version: "1.8.1"}),
 (n11: childParameter {framework: "pytorch", version: "1.8.1"})
where n11.operator = 'torch.optim.lr_scheduler.CyclicLR' and m11.operator='torch.optim.lr_scheduler.CyclicLR' and n11.parameter_order=m11.parameter_order
merge (m11) -[: oneOfParameter {dtype_order: n11.dtype_order, dtype: n11.dtype}] -> (n11);
match
 (m11: input {framework: "pytorch", version: "1.8.1"}),
 (n11: childInput {framework: "pytorch", version: "1.8.1"})
where n11.operator = 'torch.optim.lr_scheduler.CyclicLR' and m11.operator='torch.optim.lr_scheduler.CyclicLR' and n11.input_order=m11.input_order
merge (m11) -[: oneOfInput {dtype_order: n11.dtype_order, dtype: n11.dtype}] -> (n11);
match
 (m11: return {framework: "pytorch", version: "1.8.1"}),
 (n11: childReturn {framework: "pytorch", version: "1.8.1"})
where n11.operator = 'torch.optim.lr_scheduler.CyclicLR' and m11.operator='torch.optim.lr_scheduler.CyclicLR' and n11.return_order=m11.return_order
merge (m11) -[: oneOfReturn {dtype_order: n11.dtype_order, dtype: n11.dtype}] -> (n11);
